p8105_hw2_es3866
================
2024-09-27

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(dplyr)
```

\##Problem 1: \# Use relative path to upload the datasets

``` r
pols_df = read_csv(file = "./fivethirtyeight_datasets/pols-month.csv")
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
pols_df = janitor::clean_names(pols_df)
```

# Clean the data in pols-month.csv.

Use separate() to break up the variable mon into integer variables year,
month, and day.

``` r
pols_df <- pols_df %>%
  separate(mon, c("year", "month", "day"))
```

Replace month number with month name.

``` r
pols_df <- pols_df %>%
  mutate(
    month = as.integer(.data$month),
    month = month.name[month]) %>%
  mutate(year = as.integer(year))
```

Create a president variable taking values gop and dem. The pivot
function automatically gets rid of prez_gop and prez_dem.

``` r
pols_df <- pols_df %>%
    pivot_longer(
      cols = c(prez_gop, prez_dem),
      names_to = "president",
      values_to = "party"
  )
```

Remove the day variable.

``` r
pols_df <- pols_df %>%
  select(-day)
```

# Clean the data in snp.csv

``` r
snp_df = read_csv(file = "./fivethirtyeight_datasets/snp.csv")
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_df = janitor::clean_names(snp_df)
```

Break up the data variables into day, month, and year

``` r
snp_df <- snp_df %>%
  separate(date, c("month", "day", "year"))
```

For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp_df <- snp_df %>%  
  mutate(
    year = as.integer(year),
    year = ifelse(year < 40, 2000 + year, 1900 + year)) %>%
  mutate(
    month = as.integer(month),
    month = month.name[month]) %>%
  select(year, month, everything())
```

Tidy the unemployment data so that it can be merged with the previous
datasets. This process will involve switching from “wide” to “long”
format; ensuring that key variables have the same name; and ensuring
that key variables take the same values.

``` r
unemployment_df = read_csv(file = "./fivethirtyeight_datasets/unemployment.csv")
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemployment_df = janitor::clean_names(unemployment_df)
```

``` r
unemployment_df <- unemployment_df %>%
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "percentage"
  )
```

``` r
unemployment_df <- unemployment_df %>%
  mutate(month = month.name[match(tolower(month), tolower(month.abb))])
```

``` r
unemployment_df <- unemployment_df %>%
  mutate(
    year = as.integer(year)
  )
```

Now, merge the data sets! Join the datasets by merging snp into pols,
and merging unemployment into the result.

``` r
snp_pols_df <- snp_df %>%
  left_join(pols_df, by = c("year", "month"))
```

``` r
merged_df <- snp_pols_df %>%
  left_join(unemployment_df, by = c("year", "month"))
```

# Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

The file “pols-month” contains 822 observations related to the number of
national politicians who are democratic or republican (senators,
representatives, govenors, president) at any given time. The snp dataset
contains 787 observations related to the S&P including the date and the
closing values of the S&P stock index on the associated date. The
unemployment dataset contains 68 observations including the year and the
percentage of unemployment in the month of the associated year.

The merged dataset contains data from the years 1950-2015 and aligns the
political state (republican vs democrat) at a given time to the S&P
index closing values and unemployment data. It appears that the
unemplyment rates increase when there is a republican president.
Overall, S&P performance has increased over time.

## Problem 2:

``` r
library(readxl) 
mr_trash <- read_excel("./202409 Trash Wheel Collection Data.xlsx",
                       sheet = 1)  %>%
                       slice(1:(n() - 1)) %>%
  mutate(wheel = "mr_trash",
         Year = as.integer(Year))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
professor_trash <- read_excel("./202409 Trash Wheel Collection Data.xlsx",
                              sheet = 2)  %>%
                              slice(1:(n() - 1)) %>%
  mutate(wheel = "professor_trash",
         Year = as.integer(Year))

gwynnda_trash <- read_excel("./202409 Trash Wheel Collection Data.xlsx",
                            sheet = 4)  %>%
                            slice(1:(n() - 1)) %>%
  mutate(wheel = "gwynnda_trash",
         Year = as.integer(Year))

# Combine them into one tidy dataset
trashwheel_df <- bind_rows(mr_trash, professor_trash, gwynnda_trash)

trashwheel_df = janitor::clean_names(trashwheel_df)
```

# Write a paragraph about these data

Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in June of 2022?

``` r
trashwheel_df %>%
  group_by(wheel) %>%
  summarise(n_obs = n())
```

    ## # A tibble: 3 × 2
    ##   wheel           n_obs
    ##   <chr>           <int>
    ## 1 gwynnda_trash     263
    ## 2 mr_trash          652
    ## 3 professor_trash   120

``` r
trashwheel_df %>%
  select(dumpster, month, year, weight_tons, cigarette_butts, wheel)
```

    ## # A tibble: 1,035 × 6
    ##    dumpster month  year weight_tons cigarette_butts wheel   
    ##       <dbl> <chr> <int>       <dbl>           <dbl> <chr>   
    ##  1        1 May    2014        4.31          126000 mr_trash
    ##  2        2 May    2014        2.74           91000 mr_trash
    ##  3        3 May    2014        3.45          105000 mr_trash
    ##  4        4 May    2014        3.1           100000 mr_trash
    ##  5        5 May    2014        4.06          120000 mr_trash
    ##  6        6 May    2014        2.71           90000 mr_trash
    ##  7        7 May    2014        1.91           56000 mr_trash
    ##  8        8 May    2014        3.7           112000 mr_trash
    ##  9        9 June   2014        2.52           98000 mr_trash
    ## 10       10 June   2014        3.76          130000 mr_trash
    ## # ℹ 1,025 more rows

How many tons did each wheel collect? Mr. Trash, it collected 2091.18
tons of trash.

``` r
trashwheel_df %>%
  group_by(wheel) %>%
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))
```

    ## # A tibble: 3 × 2
    ##   wheel           total_weight
    ##   <chr>                  <dbl>
    ## 1 gwynnda_trash           798.
    ## 2 mr_trash               2091.
    ## 3 professor_trash         247.

How many cigarette butts did gwynnda collect in June 2022? 18120

``` r
trashwheel_df %>%
  filter(wheel == "gwynnda_trash", year == 2022, month == "June") %>%
  summarise(total_cigs = sum(cigarette_butts, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   total_cigs
    ##        <dbl>
    ## 1      18120

## Problem 3

Create a single, well-organized dataset with all the information
contained in these data files. To that end: import, clean, tidy, and
otherwise wrangle each of these datasets; check for completeness and
correctness across datasets (e.g. by viewing individual datasets and
monitoring warning messages); merge to create a single, final dataset;
and organize this so that variables and observations are in meaningful
orders.

Briefly describe the resulting tidy dataset. How many total observations
exist? How many unique ZIP codes are included, and how many unique
neighborhoods?

Which ZIP codes appear in the ZIP code dataset but not in the Zillow
Rental Price dataset? Using a few illustrative examples discuss why
these ZIP codes might be excluded from the Zillow dataset.

Rental prices fluctuated dramatically during the COVID-19 pandemic. For
all available ZIP codes, compare rental prices in January 2021 to prices
in January 2020. Make a table that shows the 10 ZIP codes (along with
the borough and neighborhood) with largest drop in price from January
2020 to 2021. Comment.

Import the dataset:

``` r
zipcodes_df = read_csv(file = "./zillow_data/Zip Codes.csv")
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
zipcodes_df = janitor::clean_names(zipcodes_df)

zori_df = read_csv(file = "./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
zori_df = janitor::clean_names(zori_df)
```

Match the datasets

``` r
zipcodes_df <- zipcodes_df %>%
  mutate(
    county = as.character(county)
  )

zori_df <- zori_df %>%
  mutate(
    county_name = str_remove(county_name, " County$"),
    county_name = str_trim(county_name),
    county_name = as.character(county_name)
  )
```

Merge

``` r
zip_zori_df <- zipcodes_df %>%
  left_join(zori_df, by = c("county" = "county_name"))
```

    ## Warning in left_join(., zori_df, by = c(county = "county_name")): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 1 of `x` matches multiple rows in `y`.
    ## ℹ Row 5 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.
